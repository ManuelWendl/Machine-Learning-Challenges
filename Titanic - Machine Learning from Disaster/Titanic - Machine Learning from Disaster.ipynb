{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Titanic - Machine Learning from Disaster\n",
    "## ML Project from kaggle\n",
    "This project can be found on https://www.kaggle.com/c/titanic/data?select=train.csv\n",
    "\n",
    "### Goal\n",
    "It is your job to predict if a passenger survived the sinking of the Titanic or not.\n",
    "For each in the test set, you must predict a 0 or 1 value for the variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "train_data = np.array(train)\n",
    "columns = train.columns.values\n",
    "\n",
    "\n",
    "test_numerical, train_meta1 = pd.factorize(train[columns[4]])\n",
    "train_data[:,4] = test_numerical\n",
    "train[columns[4]] = test_numerical\n",
    "test_numerical, train_meta2 = pd.factorize(train[columns[11]])\n",
    "train_data[:,11] = test_numerical\n",
    "train[columns[11]] = test_numerical\n",
    "\n",
    "traintarget = train_data[:,1]\n",
    "traintarget =np.array(traintarget,dtype=float)\n",
    "train_data = train_data[:,[2, 4, 5, 6, 7, 9, 11]]\n",
    "train_data =np.array(train_data,dtype=float)\n",
    "train_data[np.isnan(train_data)] = 40\n",
    "traintarget[np.isnan(traintarget)] = 0\n",
    "\n",
    "for i in range(train_data.shape[1]):\n",
    "    train_data[:,i] = train_data[:,i]*0.99/np.max(train_data[:,i]) +0.01\n",
    "\n",
    "\n",
    "train_target = np.zeros((len(traintarget),2))\n",
    "for i in range(len(train_target)):\n",
    "    train_target[i,int(traintarget[i])] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementation Neural Network\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.e ** -x)\n",
    "def d_sigmoid(x):\n",
    "    return x * (1-x)\n",
    "\n",
    "activation_func = sigmoid\n",
    "d_activation_func = d_sigmoid\n",
    "\n",
    "def forward_single_layer(out_prev, w_curr, b_curr):\n",
    "        return activation_func(np.dot(w_curr, out_prev)+b_curr)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, architecture):\n",
    "        self.architecture = architecture\n",
    "        self.parameters = {}\n",
    "        for idx, layer in enumerate(architecture):\n",
    "            layer_idx = idx+1\n",
    "            layer_input = layer[\"inputs\"]\n",
    "            layer_output = layer[\"neurons\"]\n",
    "            self.parameters['W'+str(layer_idx)] = np.random.randn(layer_output,layer_input)\n",
    "            self.parameters['B'+str(layer_idx)] = np.random.randn(layer_output,1)\n",
    "\n",
    "    def forward_propagation(self, inputs):\n",
    "        inputs = np.array(inputs, ndmin=2).T\n",
    "        out_curr = inputs\n",
    "        memory = {}\n",
    "        for idx, layer in enumerate(self.architecture):\n",
    "            layer_idx = idx+1\n",
    "            w_curr = self.parameters[\"W\"+str(layer_idx)]\n",
    "            b_curr = self.parameters[\"B\"+str(layer_idx)]\n",
    "            out_curr = forward_single_layer(out_prev=out_curr,w_curr=w_curr,b_curr=b_curr)\n",
    "            memory[idx] = out_curr\n",
    "        return out_curr, memory\n",
    "\n",
    "\n",
    "    def train_iteration(self, inputs, target, learn_rate):\n",
    "        target = np.array(target, ndmin=2).T\n",
    "        output, memory = self.forward_propagation(inputs)\n",
    "        inputs = np.array(inputs, ndmin=2).T\n",
    "        loss = 0\n",
    "        for idx, layer in reversed(list(enumerate(self.architecture))):\n",
    "            layer_idx = idx+1\n",
    "            if layer_idx == len(self.architecture):\n",
    "                loss += target - output\n",
    "                adjust_w = learn_rate*1/layer[\"neurons\"]*(loss*d_activation_func(memory[idx])).dot(memory[idx-1].T)\n",
    "                adjust_b = learn_rate*1/layer[\"neurons\"]*loss*d_activation_func(memory[idx])\n",
    "                self.parameters[\"W\"+str(layer_idx)] += (adjust_w/learn_rate - adjust_b)*learn_rate\n",
    "                self.parameters[\"B\"+str(layer_idx)] += adjust_b\n",
    "            elif layer_idx == 1:\n",
    "                loss = self.parameters[\"W\"+str(layer_idx+1)].T.dot(loss)\n",
    "                adjust_w = learn_rate*1/layer[\"neurons\"]*(loss*d_activation_func(memory[idx])).dot(inputs.T)\n",
    "                adjust_b = learn_rate*1/layer[\"neurons\"]*loss*d_activation_func(memory[idx])\n",
    "                self.parameters[\"W\"+str(layer_idx)] += (adjust_w/learn_rate - adjust_b)*learn_rate\n",
    "                self.parameters[\"B\"+str(layer_idx)] += adjust_b\n",
    "            else:\n",
    "                loss = self.parameters[\"W\"+str(layer_idx+1)].T.dot(loss)\n",
    "                adjust_w = learn_rate*1/layer[\"neurons\"]*(loss*d_activation_func(memory[idx])).dot(memory[idx-1].T)\n",
    "                adjust_b = learn_rate*1/layer[\"neurons\"]*loss*d_activation_func(memory[idx])\n",
    "                self.parameters[\"W\"+str(layer_idx)] += (adjust_w/learn_rate - adjust_b)*learn_rate\n",
    "                self.parameters[\"B\"+str(layer_idx)] += adjust_b\n",
    "\n",
    "    def train(self, inputs, targets, epoches):\n",
    "        for epoch in range(epoches):\n",
    "            shuffler = np.random.permutation(len(targets))\n",
    "            inputs = inputs[shuffler]\n",
    "            targets = targets[shuffler]\n",
    "            for i in range(0,891):\n",
    "                inputdata = inputs[i,:]\n",
    "                target = targets[i,:]\n",
    "                self.train_iteration(inputdata, target, 0.1)\n",
    "            if epoch/epoches * 100 % 10 == 0:\n",
    "                print('Training Processed: '+str(epoch/epoches*100)+'%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "outputs": [],
   "source": [
    "NN_architecture = [\n",
    "    {\"inputs\":7, \"neurons\":5},\n",
    "    {\"inputs\":5, \"neurons\":2}\n",
    "]\n",
    "NN = NeuralNetwork(NN_architecture)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Processed: 0.0%\n",
      "Training Processed: 10.0%\n",
      "Training Processed: 20.0%\n",
      "Training Processed: 30.0%\n",
      "Training Processed: 40.0%\n",
      "Training Processed: 50.0%\n",
      "Training Processed: 60.0%\n",
      "Training Processed: 70.0%\n",
      "Training Processed: 80.0%\n",
      "Training Processed: 90.0%\n"
     ]
    }
   ],
   "source": [
    "NN.train(train_data,train_target,100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test on Train Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of prediction:  82.25 %\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "predict = np.empty((400,2))\n",
    "for i in range(400):\n",
    "    out, mem = NN.forward_propagation(train_data[i,:])\n",
    "    predict[[i],:] = out.T\n",
    "    if np.argmax(out) == np.argmax(train_target[i,:]):\n",
    "        count += 1\n",
    "performance = (count/400)*100\n",
    "print('Performance of prediction: ', performance, '%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Data for idmission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "test_data = np.array(test)\n",
    "columns = test.columns.values\n",
    "\n",
    "\n",
    "test_numerical, train_meta1 = pd.factorize(test[columns[3]])\n",
    "test_data[:,3] = test_numerical\n",
    "test[columns[3]] = test_numerical\n",
    "test_numerical, train_meta2 = pd.factorize(test[columns[10]])\n",
    "test_data[:,10] = test_numerical\n",
    "test[columns[10]] = test_numerical\n",
    "\n",
    "test_data = test_data[:,[1, 3, 4, 5, 6, 8, 10]]\n",
    "test_data =np.array(test_data,dtype=float)\n",
    "test_data[np.isnan(test_data)] = 40\n",
    "\n",
    "for i in range(test_data.shape[1]):\n",
    "    test_data[:,i] = test_data[:,i]*0.99/np.max(test_data[:,i]) +0.01"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "outputs": [],
   "source": [
    "result = np.empty(test_data.shape[0])\n",
    "for i in range(test_data.shape[0]):\n",
    "    res, mem = NN.forward_propagation(test_data[i,:])\n",
    "    result[i] = np.argmax(res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create CSV file for idmission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "outputs": [],
   "source": [
    "ID = np.arange(892, 1310, 1)\n",
    "ID = np.array(ID, ndmin=2, dtype=int).T\n",
    "result = np.array(result, ndmin=2, dtype=int).T\n",
    "sub = np.hstack((ID,result))\n",
    "\n",
    "sub = pd.DataFrame(sub, columns=['PassengerId', 'Survived'])\n",
    "sub.to_csv('sub.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}